<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="EN" lang="EN" dir="ltr" class="gr__corsmal_eecs_qmul_ac_uk">
<head profile="http://gmpg.org/xfn/11">
	<link rel="shortcut icon" href="favicon.ico" />
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

	<title>CORSMAL: OHPL: One-shot Hand-eye Policy Learner</title>

	<meta http-equiv="imagetoolbar" content="no">
	<meta http-equiv="KeyWords" content="code, software, CORSMAL, robotics, touch, vision, audio, signal processing, human behaviour, reinforcement learning">
	<meta name="image" property="og:image" content="images/CORSMAL_logo.png">
	<link rel="stylesheet" href="css/layout.css" type="text/css">
	<script type="text/javascript" src="js/jquery-1.4.1.min.js"></script>
	<script type="text/javascript" src="js/jquery.slidepanel.setup.js"></script>
	<script type="text/javascript" src="js/jquery-ui-1.7.2.custom.min.js"></script>
	<script type="text/javascript" src="js/jquery.tabs.setup.js"></script>

<link href="benchmark/dist/css/tabulator.min.css" rel="stylesheet">
<script type="text/javascript" src="benchmark/dist/js/tabulator.min.js"></script>
<link href="https://unpkg.com/tabulator-tables@4.4.3/dist/css/tabulator.min.css" rel="stylesheet">
<script type="text/javascript" src="https://unpkg.com/tabulator-tables@4.4.3/dist/js/tabulator.min.js"></script>

	<style type="text/css">
		/*tr:hover {background-color: #f5f5f5;}*/
		.tg  {border-collapse:collapse;border-spacing:0;}
		.tg td{border-color:black;border-style:solid;border-width:1px;overflow:hidden;padding:10px 5px;word-break:normal;}
		.tg th{border-color:black;border-style:solid;border-width:1px;font-weight:normal;font-size:14.0pt;overflow:hidden;padding:10px 5px;word-break:normal;}
		.tg .tg-km2t{border-color:#ffffff;font-weight:bold;font-size:14.0pt;text-align:left;vertical-align:top}
		.tg .tg-zv4m{border-color:#ffffff;font-size:14.0pt;text-align:left;vertical-align:top}
	</style>

</head>
<body id="top" data-gr-c-s-loaded="true">
	<div class="wrapper row1">
		<div id="header" class="clear">
			<div class="fl_left">
				<ul>
					<li>
						<p>
							<a href="index.html"><img src="images/CORSMAL_logo.png" style="padding:0px 0px 0px 0px;height:75px" alt="CORSMAL"></a>
						</p>
					</li>
				</ul>
			</div>
		</div>
	</div>
	<!-- 2###################################################################################################### -->
	<div class="wrapper row2" ;="" style="margin-bottom: 7px;">
		<div class="rnd">
			<!-- ###### -->
			<div id="topnav">
				<ul style="margin-top: 5px;">
					<li><a href="index.html"><b>Home</b></a></li>
					<li><a href="objectives.html"><b>Objectives</b></a></li>
					<li><a href="publications.html"><b>Publications</b></a></li>
					<li><a href="blog.html"><b>Blog</b></a></li>
					<li><a href="events.html"><b>Events</b></a></li>
					<li><a href="code.html"><b>Code</b></a></li>
					<li><a href="data.html"><b>Data</b></a></li>
					<li><a href="benchmark.html"><b>Benchmark</b></a></li>
				<li class="last"><a href="challenge.html"><b>Challenge</b></a></li>
				</ul>
			</div>
			<!-- ###### -->
		</div>
	</div>
	<!-- 3####################################################################################################### -->
	<div class="wrapper row1">
		<div id="container" class="clear">
			<div id="latestnewspage" class="clear">

				<h1><p class="xmsonormal" style="text-align:center;text-justify:inter-ideograph;margin-bottom:0px"><b><span style="font-size:16.0pt">OHPL: One-shot Hand-eye Policy Learner</span></b></p></h1>
				<p align="justify"> 
					The control of a robot for manipulation tasks generally relies on object detection and pose estimation. An attractive alternative is to learn control policies directly from raw input data. However, this approach is time-consuming and expensive since learning the policy requires many trials with robot actions in the physical environment. To reduce the training cost, the policy can be learned in simulation with a large set of synthetic images. The limit of this approach is the domain gap between the simulation and the robot workspace.
				</p>
				<p align="justify"> 
					We propose to learn a policy for robot reaching movements from a single image captured directly in the robot workspace from a camera placed on the end-effector (a hand-eye camera). The idea behind the proposed policy learner is that view changes seen from the hand-eye camera produced by actions in the robot workspace are analogous to locating a region-of-interest in a single image by performing sequential object localisation. This similar view change enables training of object reaching policies using reinforcement-learning-based sequential object localisation.
				</p>
				<p align="justify"> 
					To facilitate the adaptation of the policy to view changes in the robot workspace, we further present a dynamic filter that learns to bias an input state to remove irrelevant information for an action decision. The proposed policy learner can be used as a powerful representation for robotic tasks, and we validate it on static and moving object reaching tasks.
				</p>
				<p align="center">
					<video width="600" controls="" autoplay loop muted> <source src="resources/OHPL/overview.mp4" type="video/mp4"> Your browser does not support HTML5 video. </video>
				</p>
				<br><br>
				<p class="xmsonormal" style="text-justify:inter-ideograph;margin-bottom:0px"><b><span style="font-size:14.0pt">Problem definition</span></b>
				<p align="justify"> 
					We consider our approach for the task of closed-loop object reaching via discrete actions. Our 6 DoF robot arm (UR5) is equipped with a two-finger parallel gripper <a href="https://robotiq.com/products/2f85-140-adaptive-robot-gripper"><u>(Robotiq 2F-85)</u></a> with a camera mounted on top indicated by the green block which we refer to as the hand-eye camera. The agent receives RGB images from the hand-eye camera at each timestep and performs an action out of a set of 7 discrete actions. The goal of the task is for the robot to reach a predefined target area in front of the object indicated by the yellow box.
				</p>
				<p align="center"> 
					<img src="images/OHPL/problem_def.png" style="padding:0px 0px 0px 0px;height:250px" alt="">	
				</p>
				<br><br>
				<p class="xmsonormal" style="text-justify:inter-ideograph;margin-bottom:0px"><b><span style="font-size:14.0pt">Learning to reach from a single image via a proxy task</span></b>
				<p align="justify"> 
					We first train the agent in the proxy task of sequential object localization using <a href="https://arxiv.org/pdf/1312.5602.pdf"><u>deep Q-learning</u></a>. We use a convolutional neural network to represent the Q-network and we use <a href="https://arxiv.org/pdf/1605.09673.pdf"><u>dynamic filters</u></a> as soft-attention to provide effective information as input to the Q-network for localisation. We train a separate model for each individual object which is selected from the <a href="https://www.ycbbenchmarks.com/object-models/"><u>YCB dataset</u></a>. Once the agent is trained we save the model and deploy it directly to perform the object reaching task in the robot work space. The agent performs the corresponding action in the robot workspace according to the predefined mapping. The task is considered to be completed successfully when the robot moves to a target location in front of the object.
				</p>
				<p align="center">
					<video width="600" controls="" autoplay loop muted> <source src="resources/OHPL/proxy_task.mp4" type="video/mp4"> Your browser does not support HTML5 video. </video>
				</p>
				<br><br>
				<p class="xmsonormal" style="text-justify:inter-ideograph;margin-bottom:0px"><b><span style="font-size:14.0pt">Validation: Object reaching</span></b>
				<p align="justify"> 
					We validate the OHPL agent, trained from the proxy task, in a robot simulation workspace for the static and moving object reaching task in <a href="https://pybullet.org/wordpress/"><u>PyBullet</u></a>. In the moving object reaching task, we randomise the velocity of the object in the x, y and z directions. The same success criteria from the static object reaching task is used. We also trained a model called scratch which is trained directly in the simulated robot workspace for the static object reaching task as an upper bound on the performance as there is no domain gap. Experiments are performed on all 8 objects in 3 lighting conditions and 9 starting positions. 3 trials are performed for each combination so a total of 648 experiments are performed for each model.
				</p>
				<p align="center">
					<video width="600" controls="" autoplay loop muted> <source src="resources/OHPL/training.mp4" type="video/mp4"> Your browser does not support HTML5 video. </video>
				</p>
				<br><br>
				<p class="xmsonormal" style="text-justify:inter-ideograph;margin-bottom:0px"><b><span style="font-size:14.0pt">Example of static-object reaching</span></b>
					<table align="center" style="border:0px;padding-left:0px">
						<tbody>
						<tr>
							<th style="border:1px solid black;padding:0px;vertical-align: middle;" width="210px" align="center">Scratch</th>
							<th style="border:1px solid black;padding:0px;vertical-align: middle;" width="210px" align="center">Scratch (with dynamic filters)</th>
							<th style="border:1px solid black;padding:0px;vertical-align: middle;" width="210px" align="center">OHPL</th>
							<th style="border:1px solid black;padding:0px;vertical-align: middle;" width="210px" align="center">OHPL (with dynamic filters)</th>
						</tr>
						<tr>
							<td style="border:1px solid black;padding:0px" align="center"><video width="210" controls=""> <source src="resources/OHPL/static_scratch_base.mp4" type="video/mp4"> Your browser does not support HTML5 video. </video></td>
							<td style="border:1px solid black;padding:0px" align="center"><video width="210" controls=""> <source src="resources/OHPL/static_scratch_dyn.mp4" type="video/mp4"> Your browser does not support HTML5 video. </video></td>
							<td style="border:1px solid black;padding:0px" align="center"><video width="210" controls=""> <source src="resources/OHPL/static_ohpl_base.mp4" type="video/mp4"> Your browser does not support HTML5 video. </video></td>
							<td style="border:1px solid black;padding:0px" align="center"><video width="210" controls=""> <source src="resources/OHPL/static_ohpl_dyn.mp4" type="video/mp4"> Your browser does not support HTML5 video. </video></td>
						</tr>
						</tbody>
					</table>
				<br><br>
				<p class="xmsonormal" style="text-justify:inter-ideograph;margin-bottom:0px"><b><span style="font-size:14.0pt">Example of moving-object reaching</span></b>
					<table align="center" style="border:0px;padding-left:0px">
						<tbody>
						<tr>
							<th style="border:1px solid black;padding:0px;vertical-align: middle;" width="225px" align="center">Scratch</th>
							<th style="border:1px solid black;padding:0px;vertical-align: middle;" width="225px" align="center">Scratch (with dynamic filters)</th>
							<th style="border:1px solid black;padding:0px;vertical-align: middle;" width="225px" align="center">OHPL</th>
							<th style="border:1px solid black;padding:0px;vertical-align: middle;" width="225px" align="center">OHPL (with dynamic filters)</th>
						</tr>
						<tr>
							<td style="border:1px solid black;padding:0px" align="center"><video width="225" controls=""> <source src="resources/OHPL/moving_scratch_base.mp4" type="video/mp4"> Your browser does not support HTML5 video. </video></td>
							<td style="border:1px solid black;padding:0px" align="center"><video width="225" controls=""> <source src="resources/OHPL/moving_scratch_dyn.mp4" type="video/mp4"> Your browser does not support HTML5 video. </video></td>
							<td style="border:1px solid black;padding:0px" align="center"><video width="225" controls=""> <source src="resources/OHPL/moving_ohpl_base.mp4" type="video/mp4"> Your browser does not support HTML5 video. </video></td>
							<td style="border:1px solid black;padding:0px" align="center"><video width="225" controls=""> <source src="resources/OHPL/moving_ohpl_dyn.mp4" type="video/mp4"> Your browser does not support HTML5 video. </video></td>
						</tr>
						</tbody>
					</table>
				<br><br>
				<p class="xmsonormal" style="text-justify:inter-ideograph;margin-bottom:0px"><b><span style="font-size:14.0pt">Related material</span></b>
				</p>
				<!-- <a href="https://ieeexplore.ieee.org/document/9054112" target="_blank"><u>Paper </u></a> -->
				<a href="https://arxiv.org/pdf/2108.03318.pdf" target="_blank"><u>Pre-print (arXiv)</u></a>
				<br><br><br>
				<h3><span style="font-size:14.0pt"><b>Acknowledgments</b></span></h3>
				<p>
					<!-- If you use the code, please cite:<br> -->
					<a href="https://arxiv.org/pdf/2108.03318.pdf" TARGET = "_blank"><b>OHPL: One-shot Hand-eye Policy Learner</b></a><br>
					C. Oh, Y. Pang and A. Cavallaro<br>
					IEEE International Conference on Intelligent Robots and Systems (IROS), Virtual, 27 September - 01 October 2021.
				</p>
			</div>	
		</div>
	</div>

<!-- ####################################################################################################### -->
<!-- Begin of Sponsors and Partners div -->
<div class="wrapper row1">
	<div id="header" class="clear" style="padding: 0px 0px 0px 20px;width:920px">
		<div class="fl_left" style="margin-top: 0px;">
			<ul>
				<li style="padding: 0 0 0 0">
					<p>
						<b>Sponsors</b>
						<br>
						<br>
					</p>
					<p>
						<a href="http://www.chistera.eu" TARGET = "_blank"><img src="images/chist-era_logo_crop.png" style="height:35px;" alt="Chistera logo"/></a>
						<a href="https://epsrc.ukri.org/" target="_blank"><img src="images/EPSRC_logo.png" style="padding:10px 0px 0px 10px;height:35px;margin-bottom: 10px;" alt="EPSRC logo"></a>
						<a href="http://www.agence-nationale-recherche.fr/en/" target="_blank"><img src="images/ANR_logo.png" style="padding:10px 0px 0px 10px;height:35px;margin-bottom: 10px;" alt="ANR logo"></a>
						<a href="http://www.snf.ch/en/Pages/default.aspx" target="_blank"><img src="images/FNS_logo.jpg" style="padding:10px 0px 0px 10px;height:35px;margin-bottom: 10px;" alt="FNS logo"></a>
					</p>
				</li>
			</ul>
		</div>
		<div class="fl_right" style="margin-top: 0px;">
			<ul style="margin-bottom: 0px;">
				<li style="margin: 0px 4px 0px 0; padding: 0 0px 0 0;">
					<p>
						<b>Partners</b>
						<br>
						<br>
					</p>
					<p>
						<a href="https://www.qmul.ac.uk/" target="_blank"><img src="images/QMUL_logo.jpg" alt="Queen Mary University of London" style="padding:5px 10px 0px 0px;height:45px;"></a>
						<a href="http://www.sorbonne-universite.fr/en" target="_blank">
							<img src="images/Sorbonne_University_logo.png" alt="Sorbonne University" style="padding:5px 10px 0px 0px;height:45px;">
						</a>
						<a href="https://www.epfl.ch/en/home/" target="_blank">
							<img src="images/EPFL_logo.png" alt="EPFL" style="padding:5px 0px 0px 0px;height:45px;">
						</a>
					</p>
				</li>
			</ul>
		</div>
	</div>
</div>
<!-- End of Sponsors and Partners div -->
<br><br>
<!-- ####################################################################################################### -->
<!-- <div class="clearing">&nbsp;</div>-->
<div class="wrapper bottomPg">
	<div id="copyright">
		<div id="fl_left" style="font-size:12px">
			© Copyright CORSMAL 2019-2022
		</div>	  
	</div>
</div>
<!-- footer -->
<!--added to clear error with content element -->
</body>
</html>
