<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="EN" lang="EN" dir="ltr">
<head profile="http://gmpg.org/xfn/11">
<link rel="shortcut icon" href="favicon.ico" />

<title>CORSMAL: Collaborative object recognition, shared manipulation and learning | Publications</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="imagetoolbar" content="no" />
<meta http-equiv="KeyWords" content="Publications, CORSMAL, robotics, touch, vision, audio, signal processing, human behaviour"/>
<meta name="image" property="og:image" content="images/CORSMAL_logo.png">
<link rel="stylesheet" href="css/layout.css" type="text/css" />
<script type="text/javascript" src="js/jquery-1.4.1.min.js"></script>
<script type="text/javascript" src="js/jquery.slidepanel.setup.js"></script>
<script type="text/javascript" src="js/jquery-ui-1.7.2.custom.min.js"></script>
<script type="text/javascript" src="js/jquery.tabs.setup.js"></script>

<style type="text/css">
	tr:hover {background-color: #f5f5f5;}
	.tg  {border-collapse:collapse;border-spacing:0;}
	.tg td{border-color:black;border-style:solid;border-width:1px;overflow:hidden;padding:10px 5px;word-break:normal;}
		.tg th{border-color:black;border-style:solid;border-width:1px;font-weight:normal;font-size:12.0pt;overflow:hidden;padding:10px 5px;word-break:normal;}
			.tg .tg-km2t{border-color:#ffffff;font-weight:bold;font-size:12.0pt;text-align:left;vertical-align:top}
			.tg .tg-zv4m{border-color:#ffffff;font-size:13.0pt;text-align:left;vertical-align:top}
</style>


</head>
<body id="top">
<div class="wrapper row1">
  <div id="header" class="clear">
	<div class="fl_left">
	<ul>
		<li>
			<p>
			<a href="index.html"><img src="images/CORSMAL_logo.png" style="padding:0px 0px 0px 0px;height:75px" alt="CORSMAL"/></a>
			</p>
		</li>
	</ul>
    </div>
  </div>
</div>
<!-- 2###################################################################################################### -->
<div class="wrapper row2"; style="margin-bottom: 7px;">
  <div class="rnd">
    <!-- ###### -->
    <div id="topnav">
      <ul style="margin-top: 5px;">
				<li><a href="index.html"><b>Home</b></a></li>
				<li><a href="objectives.html"><b>Objectives</b></a></li>
				<li class="active"><a href="publications.html"><b>Publications</b></a></li>
				<li ><a href="blog.html"><b>Blog</b></a></li>
				<li ><a href="events.html"><b>Events</b></a></li>
				<li ><a href="code.html"><b>Code</b></a></li>
				<li><a href="data.html"><b>Data</b></a></li>
				<li><a href="benchmark.html"><b>Benchmark</b></a></li>
				<li><a href="challenge.html"><b>Challenge</b></a></li>
				<li class="last"><a href="team.html"><b>Team</b></a></li>
      </ul>
    </div>
    <!-- ###### -->
  </div>
</div>
<!-- 3####################################################################################################### -->
<div class="wrapper row1">
	<div id="container" class="clear">
		<div id="latestnewspage" class="clear">
		  <!--<h2>About us</h2>-->
		  <h2><p class=xmsonormal style='text-align:justify;text-justify:inter-ideograph'><b><span
			style='font-size:16.0pt'>Publications</span></b><o:p></o:p></p></h2>
		
			<table class="tg" width="100%">
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://doi.org/10.1109/LRA.2025.3562790" TARGET = "_blank">
							<img src="https://kerolex.github.io/images/pang24stereoho.jpg" alt="" width="200"/><br>
							</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Stereo Hand-Object Reconstruction for Human-to-Robot Handover</b><br>
							Y. L. Pang, A. Xompero, C. Oh, A. Cavallaro<br>
							IEEE Robotics and Automation Letters, Vol.10, n.6, June 2025.<br>
							IEEE/RSJ Int. Conf. Intell. Robots and Systems (IROS), Hangzhou, China, 19-25 October 2025.<br>
							[<a href="https://doi.org/10.1109/LRA.2025.3562790" TARGET = "_blank"><u>paper</u></a>]
              [<a href="https://doi.org/10.48550/arXiv.2412.07487" TARGET = "_blank"><u>arxiv</u></a>]
              [<a href="https://github.com/QM-IPAlab/StereoHO" TARGET = "_blank"><u>code</u></a>]
            	[<a href="https://qm-ipalab.github.io/StereoHO/" TARGET = "_blank"><u>webpage</u></a>]
            	[<a href="https://qm-ipalab.github.io/StereoHO/static/videos/iros_final_720_compress.mp4" TARGET = "_blank"><u>video</u></a>]
            	<!-- [<a href="https://qm-ipalab.github.io/StereoHO/static/videos/iros_final_720_compress.mp4" TARGET = "_blank"><u>poster</u></a>] -->
					</td>
				</tr>
				<!-- -->
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://doi.org/10.1109/TCDS.2022.3222088" TARGET = "_blank">
							<img src="images/Nuno2022TCDS.png" alt="" width="200"/><br>
							</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>The Role of Object Physical Properties in Human Handover Actions: Applications in Robotics</b><br>
							N. F. Duarte, A. Billard and J. Santos-Victor<br>
							IEEE Transactions on Cognitive and Developmental Systems, November 2022.<br>
							[<a href="https://doi.org/10.1109/TCDS.2022.3222088" TARGET = "_blank"><u>paper</u></a>]
							<!-- [<a href="https://doi.org/10.48550/arXiv.2107.12719" TARGET = "_blank"><u>arxiv</u></a>] -->
					</td>
				</tr>
				<!-- -->
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://doi.org/10.48550/arXiv.2107.12719" TARGET = "_blank">
							<img src="images/challenge/setup.png" alt="" width="200"/><br>
							</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>The CORSMAL benchmark for the prediction of the properties of containers</b><br>
							A. Xompero, S. Donaher, V. Iashin, F. Palermo, G. Solak, C. Coppola, R. Ishikawa, Y. Nagao, R. Hachiuma, Q. Liu, F. Feng, C. Lan, R. H. M. Chan, G. Christmann, J. Song, G. Neeharika, C. K. T. Reddy, D. Jain, B. U. Rehman, A. Cavallaro<br>
							IEEE Access, vol. 10, 2022.<br>
							[<a href="https://doi.org/10.1109/ACCESS.2022.3166906" TARGET = "_blank"><u>paper</u></a>]
							[<a href="https://doi.org/10.48550/arXiv.2107.12719" TARGET = "_blank"><u>arxiv</u></a>]
							[<a href="challenge2020.html"><u>details</u></a>]
					</td>
				</tr>
				<!-- -->
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://doi.org/10.48550/arXiv.2112.13547" TARGET = "_blank">
							<img src="images/prime_eccv22.png" alt="" width="200"/><br>
							</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>PRIME: A few primitives can boost robustness to common corruptions</b><br>
							A. Modas, R. Rade, G. Ortiz-Jim√©nez, S. Moosavi-Dezfooli, P. Frossard<br>
							European Conference on Computer Vision (ECCV), Tel-Aviv, Israel, 23-27 October 2022<br>
							<!-- [<a href="https://doi.org/10.1109/ACCESS.2022.3166906" TARGET = "_blank"><u>paper</u></a>] -->
							[<a href="https://doi.org/10.48550/arXiv.2112.13547" TARGET = "_blank"><u>arxiv</u></a>]
							<!-- [<a href="challenge2020.html"><u>details</u></a>] -->
							[<a href="https://github.com/amodas/PRIME-augmentations" TARGET = "_blank"><u>code</u></a>]
					</td>
				</tr>
				<!-- -->
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://doi.org/10.48550/arXiv.2203.04027" TARGET = "_blank">
							<img src="images/da_filling_eusipco22.png" alt="" width="200"/><br>
							</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Data augmentation with mixtures of max-entropy transformations for filling-level classification</b><br>
							A. Modas, A. Cavallaro, P. Frossard<br>
							European Signal Processing Conference (EUSIPCO), Belgrade, Serbia, 29 August - 2 September 2022<br>
							<!-- [<a href="https://doi.org/10.1109/ACCESS.2022.3166906" TARGET = "_blank"><u>paper</u></a>] -->
							[<a href="https://doi.org/10.48550/arXiv.2203.04027" TARGET = "_blank"><u>arxiv</u></a>]
							[<a href="https://youtu.be/qNKUk_G2tec" TARGET = "_blank"><u>video</u></a>]
							<!-- [<a href="challenge2020.html"><u>details</u></a>] -->
					</td>
				</tr>
				<!-- -->
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="challenge.html" TARGET = "_blank">
							<img src="images/challenge/overviewpaper_main.png" alt="" width="200"/><br>
							<img src="images/challenge/diagram_tasks.png" alt="" width="200"/><br>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Audio-Visual Object Classification for Human-Robot Collaboration</b><br>
							A. Xompero, Y. L. Pang, T. Patten, A. Prabhakar, B. Calli, A. Cavallaro<br>
							IEEE International Conference on Acoustic, Speech and Signal Processing (ICASSP), Singapore and Virtual, 22-27 May 2022.<br>
							[<a href="https://doi.org/10.1109/ICASSP43922.2022.9746336" TARGET = "_blank"><u>paper</u></a>]
							[<a href="https://doi.org/10.48550/arXiv.2203.01977" TARGET = "_blank"><u>arxiv</u></a>]
							[<a href="challenge.html"><u>details</u></a>]
							[<a href="https://youtu.be/zs_M8sU1Kzs" TARGET = "_blank"><u>video</u></a>]
							<!-- [<a href="https://youtu.be/yJ51a4e3v-Q" TARGET = "_blank"><u>slides</u></a>] -->
							[<a href="resources/challenge/CORSMAL__ICASSP2022_poster.pdf"><u>poster</u></a>]
					</td>
				</tr>
				<!-- -->
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://doi.org/10.1109/ICAR53236.2021.9659354" TARGET = "_blank">
							<img src="images/Kissoum2021ICAR_crop.png" alt="" width="200"/><br>
							</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Simultaneous Tactile Localization and Reconstruction of an Object during Robotic Manipulation</b><br>
							G. Kissoum, V. Perdereau<br>
							International Conference on Advanced Robotic (ICAR), 6-10 December 2021.<br>
							[<a href="https://doi.org/10.1109/ICAR53236.2021.9659354" TARGET = "_blank"><u>paper</u></a>]
							<!-- [<a href="https://doi.org/10.48550/arXiv.2107.12719" TARGET = "_blank"><u>arxiv</u></a>] -->
					</td>
				</tr>
				<!-- -->
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="" TARGET = "_blank">
							<img src="images/AIHRI21.png" alt="AI-HRI21" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Multimodal Sensory Learning for Real-time, Adaptive Manipulation</b><br>
							A. Prabhakar, S. Furrer, L. Panchetti, M. Perret, and A. Billard<br>
							Artificial Intelligence for Human-Robot Interaction (AI-HRI), AAAI Fall Symposium Series, Virtual, 4-6 Nov 2021.<br>
							<!-- [<a href="https://arxiv.org/abs/2110.04634" TARGET = "_blank"><u>paper</u></a>] -->
							[<a href="https://arxiv.org/abs/2110.04634" TARGET = "_blank"><u>arxiv</u></a>]
							[<a href="https://youtu.be/yJ51a4e3v-Q" TARGET = "_blank"><u>video</u></a>]
							[<a href="https://doi.org/10.5281/zenodo.6372437" TARGET = "_blank"><u>dataset</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://arxiv.org/abs/2108.03318" TARGET = "_blank">
							<img src="images/ohpl.png" alt="IROS21" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>OHPL: One-shot Hand-eye Policy Learner</b><br>
							C. Oh, Y. L. Pang, and A. Cavallaro<br>
							IEEE International Conference on Intelligent Robots and Systems (IROS), Virtual, 27 Sep - 1 Oct 2021.<br>
							[<a href="https://doi.org/10.1109/IROS51168.2021.9636835" TARGET = "_blank"><u>paper</u></a>]
							[<a href="hhttps://doi.org/10.48550/arXiv.2108.03318" TARGET = "_blank"><u>arxiv</u></a>]
							[<a href="OHPL.html"><u>details</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://arxiv.org/abs/2107.01309" TARGET = "_blank">
							<img src="images/real2sim_setup.png" alt="RO-MAN21" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Towards safe human-to-robot handovers of unknown containers</b><br>
							Y. L. Pang, A. Xompero, C. Oh, and A. Cavallaro<br>
							IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), Virtual, 8-12 Aug 2021.<br>
							[<a href="https://doi.org/10.1109/RO-MAN50785.2021.9515350" TARGET = "_blank"><u>paper</u></a>]
							[<a href="https://doi.org/10.48550/arXiv.2107.01309" TARGET = "_blank"><u>arxiv</u></a>]
							[<a href="safe_handover.html"><u>details</u></a>]
							[<a class="papercite_pdf" title="Download" href="resources/safe_ho/2021.07.01_ROMAN_Video_Pang_Xompero_Oh_Cavallaro_slides.pdf"><u>slides</u></a>]
							[<a href="https://youtu.be/QzdaSSgzlcM" TARGET = "_blank"><u>video</u></a>]
							[<a href="https://github.com/CORSMAL/safe_handover/" target="_blank"><u>code</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://arxiv.org/pdf/2102.04057.pdf" TARGET = "_blank">
							<img src="images/RTL/abstract.png" alt="ICIP21" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Improving filling level classification with adversarial training</b><br>
							A. Modas, A. Xompero, R. Sanchez-Matilla, P. Frossard, and A. Cavallaro<br>
							IEEE International Conference on Image Processing (ICIP), Anchorage, Alaska, USA, 19-22 Sep 2021.<br>
							[<a href="https://doi.org/10.1109/ICIP42928.2021.9506112" TARGET = "_blank"><u>paper</u></a>]
							[<a href="https://doi.org/10.48550/arXiv.2102.04057" TARGET = "_blank"><u>arxiv</u></a>]
							[<a href="filling.html"><u>details</u></a>]
							[<a class="papercite_pdf" title="Download" href="https://sigport.org/sites/default/files/docs/AModas_poster_ICIP.pdf" target="_blank"><u>poster</u></a>]
							[<a class="papercite_pdf" title="Download" href="https://sigport.org/sites/default/files/docs/AModas_presentation_ICIP.pdf" target="_blank"><u>slides</u></a>]
							[<a href="https://youtu.be/naVkHtwtLTY" TARGET = "_blank"><u>video</u></a>]
							<!-- [<a href="https://github.com/CORSMAL/ACC/" target="_blank"><u>code</u></a>] -->
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://arxiv.org/pdf/2103.15999.pdf" TARGET = "_blank">
							<img src="images/acc_image.png" alt="EUSIPCO21" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Audio classification of the content of food containers and drinking glasses</b><br>
							S. Donaher, A. Xompero, and A. Cavallaro<br>
							European Signal Processing Conference (EUSIPCO), Virtual, 23-27 August 2021.<br>
							[<a href="https://doi.org/10.23919/EUSIPCO54536.2021.9616206" TARGET = "_blank"><u>paper</u></a>]
							[<a href="https://doi.org/10.48550/arXiv.2103.15999" TARGET = "_blank"><u>arxiv</u></a>]
							[<a href="audio_classification.html"><u>details</u></a>]
							[<a class="papercite_pdf" title="Download" href="resources/presentations/20210827_EUSIPCO_Donaher_Xompero_Cavallaro_slides.pdf"><u>slides</u></a>]
							[<a href="https://youtu.be/8vNTZqb8NSg" TARGET = "_blank"><u>video</u></a>]
							[<a href="https://github.com/CORSMAL/ACC/" target="_blank"><u>code</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://ieeexplore.ieee.org/document/9348948" TARGET = "_blank">
							<img src="images/boundary_sketch.png" alt="Optimism in the Face of Adversity" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Optimism in the Face of Adversity: Understanding and Improving Deep Learning Through Adversarial Robustness</b><br>
							G. Ortiz-Jimenez, A. Modas, S.-M. Moosavi-Dezfooli, and P. Frossard<br>
							Proceedings of the IEEE, vol. 109, no. 5, pp. 635-659, May 2021.<br>
							<!-- DOI: https://doi.org/10.1109/JPROC.2021.3050042 -->
							[<a href="https://doi.org/10.1109/JPROC.2021.3050042" TARGET = "_blank"><u>paper</u></a>]
							[<a href="https://doi.org/10.48550/arXiv.2010.09624" TARGET = "_blank"><u>arxiv</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="resources/2020.10.29_CORSMAL_ICDL-EpiRob_paper.pdf" TARGET = "_blank">
							<img src="images/carefulness.png" alt="ICDL-EpiRob" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>From human action understanding to robot action execution: how the physical properties of handled objects modulate non-verbal cues</b><br>
							N. Ferreira Duarte, K. Chatzilygeroudis, J. Santos-Victor, and A. Billard<br>
							Joint IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob), 26-30 October 2020.<br>
							<!-- URL: https://infoscience.epfl.ch/record/284673?&ln=en -->
							[<a href="https://doi.org/10.1109/ICDL-EpiRob48136.2020.9278084" TARGET = "_blank"><u>paper</u></a>]
							[<a href="resources/2020.10.29_CORSMAL_ICDL-EpiRob_paper.pdf" TARGET = "_blank"><u>open access</u></a>]
							[<a href="https://www.youtube.com/watch?v=4Et36pMfkAo" TARGET = "_blank"><u>video</u></a>]
							[<a href="https://github.com/NunoDuarte/carefull-detection" target="_blank"><u>code</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://proceedings.neurips.cc/paper/2020/file/1ea97de85eb634d580161c603422437f-Paper.pdf" TARGET = "_blank">
							<img src="images/HoldMeTight.png" alt="Hold Me Tight" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Hold me tight! Influence of discriminative features on deep network boundaries</b><br>
							G. Ortiz-Jimenez, A. Modas, S.-M. Moosavi-Dezfooli, and P. Frossard<br>
							Advances in Neural Information and Processing Systems (NeurIPS) 34, 6-12 December 2020.<br>
							[<a href="https://proceedings.neurips.cc/paper/2020/file/1ea97de85eb634d580161c603422437f-Paper.pdf" TARGET = "_blank"><u>paper</u></a>]
							[<a href="https://doi.org/10.48550/arXiv.2002.06349" TARGET = "_blank"><u>arxiv</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://arxiv.org/abs/2006.09717" TARGET = "_blank">
							<img src="images/NeuralAnisotropy.png" alt="Neural anisotropy" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Neural anisotropy directions</b><br>
							G. Ortiz-Jimenez*, A. Modas*, S.-M. Moosavi-Dezfooli, and P. Frossard<br>
							Advances in Neural Information and Processing Systems (NeurIPS) 34, 6-12 December 2020.<br>
							[<a href="https://proceedings.neurips.cc/paper/2020/file/cff02a74da64d145a4aed3a577a106ab-Paper.pdf" TARGET = "_blank"><u>paper</u></a>]
							[<a href="https://doi.org/10.48550/arXiv.2006.09717" TARGET = "_blank"><u>arxiv</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="resources/2020.07.17_CORSMAL_ICML_UDL_paper.pdf" TARGET = "_blank">
							<img src="images/cifar.png" alt="CIFAR" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Redundant Features can Hurt Robustness to Distribution Shift</b><br>
							G. Ortiz-Jimenez, A. Modas, S. Moosavi-Dezfooli, and P. Frossard<br>
							International Conference on Machine Learning, Workshop on Uncertainty & Robustness in Deep Learning (ICML-UDL), July 17, 2020.<br>
							[<a href="resources/2020.07.17_CORSMAL_ICML_UDL_paper.pdf" TARGET = "_blank"><u>open access</u></a>]
							[<a href="https://doi.org/10.48550/arXiv.2002.06349" TARGET = "_blank"><u>arxiv</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://ieeexplore.ieee.org/abstract/document/9127857" TARGET = "_blank">
							<img src="images/spm.png" alt="SPM" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Towards Robust Sensing for Autonomous Vehicles: An Adversarial Perspective</b><br>
							A. Modas, R. Sanchez-Matilla, P. Frossard, and A. Cavallaro<br>
							IEEE Signal Processing and Magazine (SPM), vol. 37, no. 4, July 2020.<br>
							[<a href="https://doi.org/10.1109/MSP.2020.2985363" TARGET = "_blank"><u>paper</u></a>]
							[<a href="https://doi.org/10.48550/arXiv.2007.10115" TARGET = "_blank"><u>arxiv</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="ColorFool.html" TARGET = "_blank">
							<img src="images/colorfool_preview2.png" alt="ColorFool" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>ColorFool: Semantic Adversarial Colorization</b><br>
							A. S. Shamsabadi, R. Sanchez-Matilla, and A. Cavallaro<br>
							IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Seattle, Washington, 16-18 June, 2020.<br>
							[<a href="https://doi.org/10.1109/CVPR42600.2020.00123" TARGET = "_blank"><u>paper</u></a>]
							[<a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Shamsabadi_ColorFool_Semantic_Adversarial_Colorization_CVPR_2020_paper.html" TARGET = "_blank"><u>open access</u></a>]
							[<a href="https://doi.org/10.48550/arXiv.1911.10891" TARGET = "_blank"><u>arxiv</u></a>]
							[<a href="ColorFool.html"><u>details</u></a>]
							[<a href="https://github.com/smartcameras/ColorFool" TARGET = "_blank"><u>code</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="LoDE.html" TARGET = "_blank">
							<img src="images/lode_img.png" alt="LoDE" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Multi-view Shape Estimation of Transparent Containers</b><br>
							A. Xompero, R. Sanchez-Matilla, A. Modas, P. Frossard, and A. Cavallaro<br>
							IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Barcelona, Spain, 4-8 May 2020.<br>
							[<a href="https://doi.org/10.1109/ICASSP40776.2020.9054112" TARGET = "_blank"><u>paper</u></a>]
							[<a href="https://doi.org/10.48550/arXiv.1911.12354" TARGET = "_blank"><u>arxiv</u></a>]
							[<a href="LoDE.html"><u>details</u></a>]
							[<a href="https://www.youtube.com/watch?v=3UquyP2QXI4" TARGET = "_blank"><u>video</u></a>]
							[<a href="https://doi.org/10.17636/corsmal2"><u>data</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="benchmark.html" TARGET = "_blank">
							<img src="benchmark/resources/handover.gif" alt="Benchmark" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
						<b>Benchmark for Human-to-Robot Handovers of Unseen Containers with Unknown Filling</b><br>
							R. Sanchez-Matilla, K. Chatzilygeroudis, A. Modas, N. Ferreira Duarte, A. Xompero, P. Frossard, A. Billard, and A. Cavallaro<br>
							IEEE Robotics and Automation Letters (RA-L), vol.5, no. 2, Apr. 2020.<br>
							[<a href="https://doi.org/10.1109/LRA.2020.2969200" TARGET = "_blank"><u>paper</u></a>]
							[<a href="benchmark.html"><u>details</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://h2t.anthropomatik.kit.edu/pdf/Starke2019.pdf" TARGET = "_blank">
							<img src="images/graspforces.png" alt="Grasp Forces" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>On Force Synergies in Human Grasping Behavior</b><br>
							J. Starke, K. Chatzilygeroudis, A. Billard, and T. Asfour<br>
							IEEE-RAS International Conference on Humanoid Robots, Toronto, Canada, 15-17 October, 2019.<br>
							[<a href="https://doi.org/10.1109/Humanoids43949.2019.9035047" TARGET = "_blank"><u>paper</u></a>]
							[<a href="https://www.epfl.ch/labs/lasa/wp-content/uploads/2019/11/ICHR19_0047_FI.pdf" TARGET = "_blank"><u>open access</u></a>]
					</td>
				</tr>
			</table>

			<br>
			<p>
				<b>Publications that used datasets and models produced by CORSMAL</b>
			</p>
			<table class="tg" width="100%">
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;" align="center">
						<a href="https://doi.org/10.48550/arXiv.2203.01192" TARGET = "_blank">
							<img src="https://github.com/Noone65536/CORSMAL-Challenge-2022-Squids/raw/main/Images/Task345.png" alt="Squids" width="200"/><br>
							<img src="https://github.com/Noone65536/CORSMAL-Challenge-2022-Squids/raw/main/Images/Task12.png" alt="Squids" width="200"/>
						</a>				
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Improving Generalization of Deep Networks for Estimating Physical Properties of Containers and Fillings</b><br>
							H. Wang, C. Zhu, Z. Ma, C. Oh<br>
							IEEE International Conference on Acoustic, Speech and Signal Processing (ICASSP), Singapore and Virtual, 22-27 May 2022.<br>
							[<a href="https://doi.org/10.1109/ICASSP43922.2022.9747349" TARGET = "_blank"><u>paper</u></a>]
							[<a href="https://doi.org/10.48550/arXiv.2203.01192" TARGET = "_blank"><u>arxiv</u></a>]
							[<a href="https://github.com/Noone65536/CORSMAL-Challenge-2022-Squids" target="_blank"><u>code</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;text-align: center;" align="center">
						<a href="https://github.com/YuigaWada/CORSMAL2021" TARGET = "_blank">
							<img src="images/challenge/keio22.png" alt="KEIO-ICS" width="160"/>
						</a>				
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Shared Transformer Encoder with Mask-based 3D Model Estimation for Container Mass Estimation</b><br>
							T. Matsubara, S. Otsuki, Y. Wada, H. Matsuo, T. Komatsu, Y. Iioka, K. Sugiura, H. Saito<br>
							IEEE International Conference on Acoustic, Speech and Signal Processing (ICASSP), Singapore and Virtual, 22-27 May 2022.<br>
							[<a href="https://doi.org/10.1109/ICASSP43922.2022.9747110" TARGET = "_blank"><u>paper</u></a>]
							<!-- [<a class="papercite_pdf" title="YouTube" href="" target="_blank"><u>video</u></a>] -->
							<!-- [<a class="papercite_pdf" title="Download" href="resources/challenge/icpr20/2021.01.15_BecauseItsTactile_slides.pdf" target="_blank"><u>slides</u></a>]  -->
							[<a href="https://github.com/YuigaWada/CORSMAL2021" target="_blank"><u>code</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://doi.org/10.48550/arXiv.2203.01207" TARGET = "_blank">
							<img src="images/challenge/visual22c.png" alt="Visual" width="200"/>
						</a>				
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Container localisation and mass estimation with an RGB-D camera</b><br>
							T. Apicella, G. Slavic, E. Ragusa, P. Gastaldo, L. Marcenaro<br>
							IEEE International Conference on Acoustic, Speech and Signal Processing (ICASSP), Singapore and Virtual, 22-27 May 2022.<br>
							[<a href="https://doi.org/10.1109/ICASSP43922.2022.9747134" TARGET = "_blank"><u>paper</u></a>]
							[<a href="https://doi.org/10.48550/arXiv.2203.01207" TARGET = "_blank"><u>arxiv</u></a>]
							[<a href="https://github.com/CORSMAL/Visual" target="_blank"><u>code</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://doi.org/10.48550/arXiv.2012.01311" TARGET = "_blank">
							<img src="images/ICPR2020/bit_paper.PNG" alt="Because It's Tactile" width="200"/>
						</a>				
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Top-1 CORSMAL Challenge 2020 submission:<br>Filling mass estimation using multi-modal observations of human-robot handovers</b><br>
							V. Iashin, F. Palermo, G. Solak, and C. Coppola<br>
							International Conference on Pattern Recognition (ICPR) 2020 Workshops and Challenges, 10-15 Jan. 2021<br>
							[<a href="https://link.springer.com/chapter/10.1007/978-3-030-68793-9_31" TARGET = "_blank"><u>paper</u></a>]
							[<a href="https://doi.org/10.48550/arXiv.2012.01311" TARGET = "_blank"><u>arxiv</u></a>]
							[<a class="papercite_pdf" title="YouTube" href="https://youtu.be/lvPMcDaXL0A" target="_blank"><u>video</u></a>]
							[<a class="papercite_pdf" title="Download" href="resources/challenge/icpr20/2021.01.15_BecauseItsTactile_slides.pdf" target="_blank"><u>slides</u></a>] 
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://link.springer.com/chapter/10.1007/978-3-030-68793-9_32" TARGET = "_blank">
							<img src="images/ICPR2020/hvrl_paper.PNG" alt="HVLR" width="200"/>
						</a>
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
							<b>Audio-Visual Hybrid Approach for Filling Mass Estimation</b><br>
							R. Ishikawa, Y. Nagao, R. Hachiuma, and H. Saito<br>
							International Conference on Pattern Recognition (ICPR) 2020 Workshops and Challenges, 10-15 Jan. 2021<br>
							[<a href="https://link.springer.com/chapter/10.1007/978-3-030-68793-9_32" TARGET = "_blank"><u>paper</u></a>]
							[<a class="papercite_pdf" title="YouTube" href="https://youtu.be/R9O4JTkmabk" target="_blank"><u>video</u></a>]
							[<a class="papercite_pdf" title="Download" href="resources/challenge/icpr20/2021.01.15_HVRL_slides.pdf" target="_blank"><u>slides</u></a>]
					</td>
				</tr>
				<tr>
					<td class="tg-zv4m" style="vertical-align: top;">
						<a href="https://link.springer.com/chapter/10.1007/978-3-030-68793-9_33" TARGET = "_blank">
							<img src="images/ICPR2020/va2mass_paper.PNG" alt="Concatenation" width="200"/>
						</a>			
					</td>
					<td class="tg-zv4m" style="vertical-align: top;">
						<b>VA2Mass: Towards the Fluid Filling Mass Estimation via Integration of Vision & Audio Learning</b><br>
						Q. Liu, F. Feng, C. Lan, and R.H.M. Chan<br>
						International Conference on Pattern Recognition (ICPR) 2020 Workshops and Challenges, 10-15 Jan. 2021<br>
						[<a href="https://link.springer.com/chapter/10.1007/978-3-030-68793-9_33" TARGET = "_blank"><u>paper</u></a>]
						[<a class="papercite_pdf" title="YouTube" href="https://youtu.be/p0mTowy1Opc" target="_blank"><u>video</u></a>]
						[<a class="papercite_pdf" title="Download" href="resources/challenge/icpr20/2021.01.15_Concatenation_slides.pdf" target="_blank"><u>slides</u></a>]
				</td>
			</tr>
		</table>
		<br>
		<br>
	</div>				
</div>
</div>


<div class="wrapper row1">
	<div id="header" class="clear" style="padding: 0px 0px 0px 20px;width:920px">
		<div class="fl_left" style="margin-top: 0px;">
			<ul>
				<li style="padding: 0 0 0 0">
					<p>
						<b>Sponsors</b>
						<br>
						<br>
					</p>
					<p>
						<a href="http://www.chistera.eu" TARGET = "_blank"><img src="images/chist-era_logo_crop.png" style="height:35px;" alt="Chistera logo"/></a>
						<a href="https://epsrc.ukri.org/" target="_blank"><img src="images/EPSRC_logo.png" style="padding:10px 0px 0px 10px;height:35px;margin-bottom: 10px;" alt="EPSRC logo"></a>
						<a href="http://www.agence-nationale-recherche.fr/en/" target="_blank"><img src="images/ANR_logo.png" style="padding:10px 0px 0px 10px;height:35px;margin-bottom: 10px;" alt="ANR logo"></a>
						<a href="http://www.snf.ch/en/Pages/default.aspx" target="_blank"><img src="images/FNS_logo.jpg" style="padding:10px 0px 0px 10px;height:35px;margin-bottom: 10px;" alt="FNS logo"></a>
					</p>
				</li>
			</ul>
		</div>
		<div class="fl_right" style="margin-top: 0px;">
			<ul style="margin-bottom: 0px;">
				<li style="margin: 0px 4px 0px 0; padding: 0 0px 0 0;">
					<p>
						<b>Partners</b>
						<br>
						<br>
					</p>
					<p>
						<a href="https://www.qmul.ac.uk/" target="_blank"><img src="images/QMUL_logo.jpg" alt="Queen Mary University of London" style="padding:5px 10px 0px 0px;height:45px;"></a>
						<a href="http://www.sorbonne-universite.fr/en" target="_blank">
							<img src="images/Sorbonne_University_logo.png" alt="Sorbonne University" style="padding:5px 10px 0px 0px;height:45px;">
						</a>
						<a href="https://www.epfl.ch/en/home/" target="_blank">
							<img src="images/EPFL_logo.png" alt="EPFL" style="padding:5px 0px 0px 0px;height:45px;">
						</a>
					</p>
				</li>
			</ul>
		</div>
	</div>
</div>

<br><br>


<!-- ####################################################################################################### -->
<!-- <div class="clearing">&nbsp;</div>-->
<div class="wrapper bottomPg">
	<div id="copyright">
		<div id="fl_left" style="font-size:12px">
			¬© Copyright CORSMAL 2019-2022
		</div>	  
	</div>
</div>
<!-- footer -->
<!--added to clear error with content element -->
</body>
</html>
